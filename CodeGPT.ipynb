{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfRs3yETDwGtk2WfhY7WOH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shawnchow7/CodeGPT/blob/main/CodeGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RgwfA1DQq9QS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT(nn.Module):\n",
        "\n",
        "    class TransformerBlock(nn.Module):\n",
        "\n",
        "        class MultiHeadedSelfAttention(nn.Module):\n",
        "\n",
        "            class SingleHeadAttention(nn.Module):\n",
        "                def __init__(self, model_dim: int, head_size: int):\n",
        "                    super().__init__()\n",
        "                    self.key_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.query_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "                    self.value_layer = nn.Linear(model_dim, head_size, bias=False)\n",
        "\n",
        "                def forward(self, embedded):\n",
        "                    k = self.key_layer(embedded)\n",
        "                    q = self.query_layer(embedded)\n",
        "                    v = self.value_layer(embedded)\n",
        "\n",
        "                    scores = q @ torch.transpose(k, 1, 2) # @ is the same as torch.matmul()\n",
        "                    context_length, attention_dim = k.shape[1], k.shape[2]\n",
        "                    scores = scores / (attention_dim ** 0.5)\n",
        "\n",
        "                    lower_triangular = torch.tril(torch.ones(context_length, context_length))\n",
        "                    mask = (lower_triangular == 0).to(device)\n",
        "                    scores = scores.masked_fill(mask, float('-inf'))\n",
        "                    scores = nn.functional.softmax(scores, dim = 2)\n",
        "\n",
        "                    return scores @ v\n",
        "\n",
        "            def __init__(self, model_dim: int, num_heads: int):\n",
        "                super().__init__()\n",
        "                self.attention_heads = nn.ModuleList()\n",
        "                for i in range(num_heads):\n",
        "                    self.attention_heads.append(self.SingleHeadAttention(model_dim, model_dim // num_heads))\n",
        "                self.compute = nn.Linear(model_dim, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "            def forward(self, embedded):\n",
        "                head_outputs = []\n",
        "                for head in self.attention_heads:\n",
        "                    head_outputs.append(head(embedded))\n",
        "                concatenated = torch.cat(head_outputs, dim = 2)\n",
        "                return self.dropout(self.compute(concatenated))\n",
        "\n",
        "        class VanillaNeuralNetwork(nn.Module):\n",
        "\n",
        "            def __init__(self, model_dim: int):\n",
        "                super().__init__()\n",
        "                self.first_linear_layer = nn.Linear(model_dim, model_dim * 4)\n",
        "                self.relu = nn.ReLU()\n",
        "                self.second_linear_layer = nn.Linear(model_dim * 4, model_dim)\n",
        "                self.dropout = nn.Dropout(0.2) # using p = 0.2\n",
        "\n",
        "            def forward(self, x):\n",
        "                return self.dropout(self.second_linear_layer(self.relu(self.first_linear_layer(x))))\n",
        "\n",
        "        def __init__(self, model_dim: int, num_heads: int):\n",
        "            super().__init__()\n",
        "            self.mhsa = self.MultiHeadedSelfAttention(model_dim, num_heads)\n",
        "            self.vanilla_nn = self.VanillaNeuralNetwork(model_dim)\n",
        "            self.layer_norm_one = nn.LayerNorm(model_dim)\n",
        "            self.layer_norm_two = nn.LayerNorm(model_dim)\n",
        "\n",
        "        def forward(self, embedded):\n",
        "            embedded = embedded + self.mhsa(self.layer_norm_one(embedded)) # skip connection\n",
        "            embedded = embedded + self.vanilla_nn(self.layer_norm_two(embedded)) # another skip connection\n",
        "            return embedded\n",
        "\n",
        "    def __init__(self, vocab_size: int, context_length: int, model_dim: int, num_blocks: int, num_heads: int):\n",
        "        super().__init__()\n",
        "        self.token_embedding = nn.Embedding(vocab_size, model_dim)\n",
        "        self.pos_embedding = nn.Embedding(context_length, model_dim)\n",
        "        self.transformer_blocks = nn.Sequential()\n",
        "        for i in range(num_blocks):\n",
        "            self.transformer_blocks.append(self.TransformerBlock(model_dim, num_heads))\n",
        "        self.layer_norm_three = nn.LayerNorm(model_dim)\n",
        "        self.vocab_projection = nn.Linear(model_dim, vocab_size)\n",
        "\n",
        "    def forward(self, context):\n",
        "        embedded = self.token_embedding(context)\n",
        "        context_length = context.shape[1]\n",
        "        positions = torch.arange(context_length).to(device)\n",
        "        embedded = embedded + self.pos_embedding(positions)\n",
        "\n",
        "        raw_output = self.vocab_projection(self.layer_norm_three(self.transformer_blocks(embedded)))\n",
        "        # raw_output is batch by context_length by vocab_size\n",
        "\n",
        "        return raw_output"
      ],
      "metadata": {
        "id": "-K-278_1rA-b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, new_chars: int, context, context_length: int, int_to_char: dict) -> str:\n",
        "    res = []\n",
        "    for i in range(new_chars):\n",
        "        if len(context.T) > context_length:\n",
        "            context = context[:, -context_length:]\n",
        "        prediction = model(context) # B, T, Vocab_Size\n",
        "        last_time_step = prediction[:, -1, :] # B, Vocab_Size\n",
        "        probabilities = nn.functional.softmax(last_time_step, dim = -1)\n",
        "        next_char = torch.multinomial(probabilities, 1)\n",
        "        context = torch.cat((context, next_char), dim = -1)\n",
        "        res.append(int_to_char[next_char.item()])\n",
        "    return ''.join(res)"
      ],
      "metadata": {
        "id": "BOHFRMyvrRrr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/gptandchill/drake-lyric-generator\n",
        "%cd drake-lyric-generator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Zi3uiE7rZaZ",
        "outputId": "c5261b37-d8ae-4fb4-83e2-65fed625e5a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'drake-lyric-generator'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), 16.53 MiB | 37.62 MiB/s, done.\n",
            "/content/drake-lyric-generator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 104\n",
        "context_length = 128\n",
        "model_dim = 252\n",
        "num_blocks = 6\n",
        "num_heads = 6\n",
        "\n",
        "model = GPT(vocab_size, context_length, model_dim, num_blocks, num_heads).to(device)\n",
        "WEIGHT_PATH = 'weights.pt' # Adjust as necessary\n",
        "model.load_state_dict(torch.load(WEIGHT_PATH))\n",
        "model.eval()\n",
        "new_chars = 5000\n",
        "context = torch.zeros(1, 1, dtype = torch.int64).to(device)\n",
        "\n",
        "int_to_char = {0: '\\n', 1: ' ', 2: '!', 3: '\"', 4: '$', 5: '%', 6: '&', 7: \"'\", 8: '(', 9: ')', 10: '*', 11: '+', 12: ',', 13: '-', 14: '.', 15: '/', 16: '0', 17: '1', 18: '2', 19: '3', 20: '4', 21: '5', 22: '6', 23: '7', 24: '8', 25: '9', 26: ':', 27: ';', 28: '?', 29: 'A', 30: 'B', 31: 'C', 32: 'D', 33: 'E', 34: 'F', 35: 'G', 36: 'H', 37: 'I', 38: 'J', 39: 'K', 40: 'L', 41: 'M', 42: 'N', 43: 'O', 44: 'P', 45: 'Q', 46: 'R', 47: 'S', 48: 'T', 49: 'U', 50: 'V', 51: 'W', 52: 'X', 53: 'Y', 54: 'Z', 55: '[', 56: ']', 57: '_', 58: 'a', 59: 'b', 60: 'c', 61: 'd', 62: 'e', 63: 'f', 64: 'g', 65: 'h', 66: 'i', 67: 'j', 68: 'k', 69: 'l', 70: 'm', 71: 'n', 72: 'o', 73: 'p', 74: 'q', 75: 'r', 76: 's', 77: 't', 78: 'u', 79: 'v', 80: 'w', 81: 'x', 82: 'y', 83: 'z', 84: '{', 85: '|', 86: '}', 87: 'à', 88: 'á', 89: 'è', 90: 'é', 91: 'ë', 92: 'ñ', 93: 'ó', 94: 'ú', 95: '\\u2005', 96: '–', 97: '—', 98: '‘', 99: '’', 100: '“', 101: '”', 102: '…', 103: '\\u205f'}"
      ],
      "metadata": {
        "id": "PUFV14LorbNL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate(model, new_chars,context,\n",
        "               context_length,\n",
        "               int_to_char))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rCcaHwbrgTG",
        "outputId": "5224a4ba-ba7f-467e-801a-fe79b4f2e540"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I don't wanna hang go a 6, had to have anything\n",
            "Oh you diamond demons realor\n",
            "(Uh, yeah) I been scirces on shit (OVO)\n",
            "Rollack on for somebody, it's not alone\n",
            "\n",
            "[Chorus: Drake]\n",
            "Vire Viral For Ronal, no Han, I know I know\"\n",
            "\"[Intro: Wayne]\n",
            "Ayy\"\n",
            "\"[Intro: Drake]\n",
            "Look, what's on, what's on, yeah\n",
            "\n",
            "[Verse 1]\n",
            "Yeah, leavin'\n",
            "I can't got should I'm up\n",
            "Sittin' up right breasexmin', it's yourself interk\n",
            "Windo with you with it, this she said that\n",
            "Cashus three so damn time is you go\n",
            "Flow your fance, you're find your without you ever mixs, I'll be findin'\n",
            "All texts and got a picker on down\n",
            "Browel your breaCheating offen them\n",
            "When chick like naws, then course\n",
            "And like Ga, Yea\"\n",
            "\"[Intro]\n",
            "You used on to do\n",
            "All when you love you missing you\n",
            "Only who you got only her\n",
            "You know who think time\n",
            "Jho's and I'm some choose life trouble\n",
            "My sistice imbalways was rain city\n",
            "That'll the way too\n",
            "The crolfrive all the decers when I know \"\"What's just get to head\n",
            "Bet your hotel, boy/MI know who you not a rash, aw yeah\n",
            "Keep your his records, I was all already)\n",
            "Damn hit been a call that you mamma\n",
            "Came Chai Rirs, man Drake alrike 40\n",
            "Feel she rest satweats, somebody elieve in hotel'\n",
            "I ain't on the way gyou handle at illoways\n",
            "And I might I heard a who\n",
            "Tolease zaneles itbelate flinter\n",
            "Always I feel like you I don't portay?\n",
            "Ayy, ayy, ayy, ayy\n",
            "Always all these quick of me leca\"\n",
            "\"[Intro]]\n",
            "Babyeah, ayy\n",
            "(Yeah\"\n",
            "\"[Verse 1: Like]\n",
            "I don't need to this first the love turnth offects another\n",
            "What omeone work\n",
            "You need making good to love like \"\"Gyo\"\"\n",
            "Started out like go partle\n",
            "You would compoly that? You just got no one like a hot on windo\n",
            "And rich wanna girl who I will happented\n",
            "(Yeah)win' money everything, yeah (40)\n",
            "\n",
            "[Verse 2: Drake]\n",
            "Jealions you got out reperr's in the load too\n",
            "Fivioutol gotta girl home to my\n",
            "Love in the spottion, and tries peosy\n",
            "You need got his at hour women and you, no, ridin' this nails is so is\n",
            "I go high sheet clurn a buts but I was boy that our picture\n",
            "I think I'll really got a mot nigga here old on the girls in the Bart (Cloll)\n",
            "Flipinin' up to sick in up the bitches 'cause\n",
            "Know clot in the Linester, I made to foot there what I would grap\n",
            "And it's our that hice of the way than we true\n",
            "Girl, there's alone\n",
            "The fucking were doin' in bed carity\n",
            "Find there[Prol Jontro]\n",
            "It a believe told\n",
            "I said you child a misse I am way\n",
            "Throw your in birthdah-up\n",
            "And yeah, ayy, it's yeah\n",
            "Yes Cheilin' hobes life for Scordodazz\n",
            "(Haha patel, ayy)\n",
            "You shut, \"\"Plus it's yours, money other provench\n",
            "You like you breakin' rick or me, momma\n",
            "You can't get stops face, you still like Drake a Mione]\n",
            "Hellprings it, they pantleing probably srip in complace\n",
            "With my Candollarior with rummen your bassing\n",
            "Trust your new for spont already\n",
            "I write you in too Mommy hot to triends with the warters, I, I hold the bottom\n",
            "I'vel with in the winter\n",
            "I don't find my quange it goeston\n",
            "And I know why you ball, bby, I'm so I'm on, where you girl\"\n",
            "\"[Here 1]\n",
            "I've perention doin' with yo, down\n",
            "You go huck like you no know one\n",
            "You would never ceplan on the wrast no same\n",
            "Get it don't enven on gettin' on to Hellat love\n",
            "All-on-Cast-dripn for smancelow I'm doing\n",
            "We still need a shot, man girl the sufflew I'm always from, time almantions sure is all I could do mine\n",
            "\n",
            "[Verse 1]\n",
            "We supple handled like go, \"\"Yous to how ya pet\n",
            "Head that I better like you all know\n",
            "Orefore the lookin', no, no, you know?\n",
            "Somethin' know I know, show man, aww\n",
            "These I had to clubics is on ower\n",
            "I wrote to the stryna get your offenself the night I'm at I'm on or the somethin' othin' in to so proch, oh\n",
            "But never been a coming them win we'll like a head the wrong\n",
            "Camour load through of there of the lowe\n",
            "You was demes from Money Bick. Yo, no, look goin' in the old\n",
            "I don't run at shoot, there's no help, oh-oh, you've motherfuckin' beilter, this shit for you, yeah\n",
            "She did, everything, ayy, always gotta nights out, I'm asting what?\n",
            "Oh, yeah, yeah, yeah\n",
            "\n",
            "[Refrain: The Mamb\n",
            "Reep stripper out of New Damphis Dands nothing\n",
            "UVerse all time (Ayes she triving, huh?)\n",
            "And griss she scity (Don't say?), ayy, ayy, ayy\n",
            "Oh,yeah, yeah, I'm sajousy in yeah\n",
            "Yeah, awtain, bitch, I'm goneps missin' in (Yeah, aw shit, ayy)\n",
            "Did I touchin', this wishin'\n",
            "So (Ayy), now yeah, yeah, yeah\n",
            "Girl, yeah, yeah\n",
            "I had to Ho!\n",
            "Yah yeah, look what I gotta write with when your spiritent?\n",
            "Coversation, let's this go\n",
            "He done ellievery dream\n",
            "Look enies, so I got some anyboke of the sice\n",
            "Then he promise I was phones they fuckin' the ones\n",
            "I need to be eature weat it and I'll never still\n",
            "D's out my song and I don't like thought's the sure\n",
            "I make friends and see they wishin' that\n",
            "No junch, you plass with you, that\n",
            "\n",
            "[Verse 1: Drake]\n",
            "Lost-nin blames pick bes-he need freezy\n",
            "Started all in like a using like girlfriend\n",
            "Ayy, ya wait did is gettin' for Fanals\n",
            "You wouldn't never get to records for your remate\n",
            "White are for sometimes, where? Yeah, yeah, ayeah\n",
            "\n",
            "[Verse 2]\n",
            "With to get a nigga with my one of tell, you throp week\n",
            "You, I'm on a new 'fit's\n",
            "You got and your hair pilson, for tood, sto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3s9tMIWQrimE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}